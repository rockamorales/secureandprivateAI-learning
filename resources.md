# Matrix Calculus

https://explained.ai/matrix-calculus/index.html

# Autoaugment Github repo

https://github.com/DeepVoltaire/AutoAugment


# Types of optimization algorithms used in NN

https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f

# Inverse cooking
https://research.fb.com/publications/inverse-cooking-recipe-generation-from-food-images/

# Pytorch Internal Architecture
http://blog.christianperone.com/2018/03/pytorch-internal-architecture-tour/

# Understanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss and all those confusing names
https://gombru.github.io/2018/05/23/cross_entropy_loss/

# Dropout for regularizing
https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/
